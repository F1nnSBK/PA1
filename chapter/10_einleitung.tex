\section{Einleitung}
% (≈ 1,5 Seiten)

% \subsection{Motivation}
% Warum Empfehlersysteme wichtig für digitalen Journalismus sind
Die digitale Transformation hat die Art und Weise, wie Nachrichten konsumiert werden, grundlegend verändert. 
Die exponentiell wachsende Informationsmenge im Internet erschwert es den Nutzern zunehmend,
relevante Inhalte zu identifizieren. Dies erzeugt einen erheblichen Bedarf an effektiven Filtermechanismen.
In diesem Kontext spielen Empfehlungssysteme (ES) eine entscheidende Rolle, 
indem sie die Informationsüberlastung von einem Hindernis für das Engagement in eine Chance für personalisierte 
Inhalte verwandeln und so die Leseerfahrung der Nutzer verbessern (\cite{wu_personalized_2022}).
Diese Personalisierung birgt jedoch die inhärente Gefahr, sogenannte Filterblasen zu erzeugen.
Eine Filterblase tritt auf, wenn einem Nutzer nur noch Artikel zu einem spezifischen Thema angezeigt werden. 
Das führt zu einer Verzerrung der Wahrnehmung von Informationen und begünstigt eine einseitige Meinungsbildung.  

Über ihre reine Filterfunktion hinaus dienen sie in der Medienbranche als Instrument zur Steigerung 
quantitativer Metriken wie Nutzerbindung, Verweildauer oder Artikel pro Sitzung.
Die empirischen Belege aus verschiedenen Domänen, darunter E-Commerce, Streaming-Dienste
und Nachrichtenportale, zeigen einen direkten kausalen Zusammenhang zwischen verbesserten
Nutzerbindungsmetriken und greifbaren finanziellen Vorteilen wie Umsatz und Abonnements.

% \subsection{Problemstellung}
Die Generierung qualitativ hochwertiger Artikel-Empfehlungen für die Nutzer von der SV-Gruppe stellt eine 
mehrdimensionale Herausforderung dar. 
Ein zentrales Gütekriterium besteht in der Balance zwischen thematischer Relevanz und inhaltlicher Diversität. 
Nur so lassen sich die Interessen der Nutzer präzise abbilden und gleichzeitig die Entstehung von Filterblasen vermeiden.

Die technische Realisierung wird durch drei primäre Faktoren erschwert:

\begin{enumerate}
    \item \textbf{Datenvolumen und Skalierbarkeit:} Das System muss über 440.000 Artikel sowie mehr als 6,5,TB an Nutzerinteraktionsdaten effizient verarbeiten können. Die performante Verknüpfung dieser beiden Datenquellen ist eine grundlegende Anforderung.
    
    \item \textbf{Item-Cold-Start-Problem:} Neu publizierte Artikel verfügen definitionsgemäß über keine oder nur sehr wenige Nutzerinteraktionen. Modelle des Collaborative Filtering (CF), wie das hier eingesetzte NCF-Modell, können für solche kalten Artikel keine Empfehlungen generieren. Es bedarf daher einer Strategie, um neue Inhalte unmittelbar nach der Veröffentlichung fair und effektiv in den Empfehlungsprozess zu integrieren. Der Ansatz des Content-Based Filtering (CBF), der auf textueller Ähnlichkeit basiert, wirkt diesem Problem entgegen.
    
    \item \textbf{Balance zwischen Relevanz und Serendipität:} Während das CBF-Modell eine hohe thematische Genauigkeit sicherstellt, birgt es die Gefahr, Nutzer in ihren bekannten Interessen zu isolieren (Filterblase). Das CF-Modell neigt hingegen zu einem Popularity Bias. Die zentrale Problemstellung dieser Arbeit liegt in der Konzeption und Optimierung einer hybriden Architektur, die diese gegensätzlichen Eigenschaften der Modelle gezielt kombiniert, um eine optimale Balance zu erreichen.
\end{enumerate}

\subsection{Zielsetzung und Aufbau der Arbeit}
\label{sec:zielsetzung}
Das primäre Ziel dieser Arbeit ist die Konzeption, Entwicklung und Optimierung eines prototypischen, 
hybriden Empfehlungssystems für die SV-Gruppe, das auf der Google Cloud Platform implementiert wird. 
Der Fokus liegt auf der Optimierung einer gewichteten Hybridisierungsstrategie, bei der die Empfehlungslisten 
eines Content-Based-Filtering- und eines Collaborative-Filtering-Modells mittels einer gewichteten Summe 
kombiniert werden. Dieser Ansatz bildet eine validierte Grundlage, auf der künftig komplexere 
Hybridisierungsarchitekturen aufbauen können (\cite{burke_hybrid_2002}).

Um die Übertragbarkeit der Resultate auf ein produktives Einsatzszenario zu gewährleisten, 
erfolgt die Evaluation des Systems auf Basis realer Nutzerdaten unter Anwendung einer strengen 
chronologischen Aufteilung von Trainings- und Testdaten. Ein weiteres Ziel besteht darin zu zeigen, 
dass bereits ein einfaches, datengetriebenes Empfehlungssystem eine deutlich höhere 
Empfehlungsqualität erzielt als Baseline-Strategien wie die zufällige 
Auswahl oder die Empfehlung populärer Artikel. (\cite{jannach_survey_2023}).

Die Arbeit ist wie folgt strukturiert:
\begin{description}
    \item[Kapitel 2] legt die theoretischen Grundlagen für Empfehlungssysteme. Es werden sowohl die in dieser Arbeit angewandten fundamentalen Techniken (CF und CBF) erläutert als auch ein Überblick über fortgeschrittene State-of-the-Art-Konzepte gegeben.
    \item[Kapitel 3] beschreibt die technische Architektur und Implementierung des Systems auf der \ac{GCP}. Der Fokus liegt auf den Anforderungen eines produktiven Systems und den gewählten Lösungsansätzen zur Erfüllung dieser Anforderungen.
    \item[Kapitel 4] präsentiert den Kern der Arbeit: die datengetriebene Optimierung der Gewichtungsfaktoren \(w_{cbf}\) und \(w_{cf}\) mittels Optuna sowie die detaillierte Darstellung und Analyse der Evaluationsergebnisse.
    \item[Kapitel 5] führt eine kritische Diskussion der erzielten Ergebnisse und beleuchtet die Limitationen der vorliegenden Arbeit. Dies schließt eine fundierte Einschätzung der Generalisierbarkeit und der praktischen Implikationen der Resultate ein.
    \item[Kapitel 6] fasst die zentralen Erkenntnisse zusammen und liefert einen Ausblick auf potenzielle Weiterentwicklungen, die auf dem hier entwickelten Prototypen aufbauen und einen inkrementellen Mehrwert generieren könnten.
\end{description}