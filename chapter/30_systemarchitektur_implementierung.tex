\section{Systemarchitektur und Rahmenbedingungen}
Die Konzeption eines produktiv einsetzbaren Empfehlungssystems für die SV-Gruppe erfordert eine Architektur, 
die klar definierten Rahmenbedingungen genügt. Aus dem Anwendungsfall lassen sich nicht-funktionale Anforderungen ableiten,
 die die technische Ausgestaltung leiten.
\label{sec:nfr}

Für den initialen Proof-of-Concept wurden drei erfolgskritische \ac{NFR}s identifiziert:
Erstens muss das System niedrige Antwortzeiten unter Last gewährleisten. Als konkretes \ac{SLO} wird eine End-to-End-Latenz 
im 95. Perzentil von unter 2000 Millisekunden angestrebt, siehe Abbildung~\ref{fig:latenz_ecdf}. Diese Anforderung orientiert sich an etablierten 
Erkenntnissen der Usability-Forschung, welche besagen, dass Antwortzeiten über einer Sekunde die Konzentration des 
Nutzers unterbrechen, während Latenzen von bis zu zehn Sekunden die Obergrenze darstellen, um die Aufmerksamkeit zu halten 
(vgl. \cite{Nielsen_Response_Times_1993}).
Zweitens ist eine horizontale Skalierbarkeit erforderlich, um auf wachsende Nutzerzahlen und Datenmengen 
im dynamischen Umfeld eines Nachrichtenportals reagieren zu können.
Drittens ist eine einfache Integrierbarkeit sicherzustellen; hierzu wird eine standardisierte REST-API bereitgestellt, 
die die Einbindung in bestehende Redaktions- und IT-Workflows vereinfacht.
\input{content/figures/latenzanalyse.tex}

Obwohl es sich um einen Prototyp handelt, wurden weitere, für einen späteren Produktivbetrieb relevante Anforderungen 
berücksichtigt: Datenschutz und Sicherheit gemäß \ac{DSGVO}, hohe Verfügbarkeit und Ausfallsicherheit sowie 
Transparenz der Empfehlungslogik zur Stärkung des Nutzervertrauens. Diese Aspekte sind im Entwurf konzeptionell verankert.

\subsection{Rahmenbedingungen}
Die bestehende, auf der \ac{GCP} basierende IT-Infrastruktur der SV-Gruppe setzt die zentralen Rahmenbedingungen. 
Der Artikelkorpus sowie die aus \ac{GA4} stammenden Nutzerinteraktionsdaten liegen in BigQuery-Tabellen vor. 
Eine zentrale Ressource bilden hochdimensionale Artikel-Embeddings (3072 Dimensionen), die aus Titeln und Volltexten 
erzeugt wurden. Da sich diese Embeddings bereits in verwandten Anwendungsfällen innerhalb der \ac{SV-Gruppe} 
(z.B. semantische Anzeigenausspielung) als qualitativ hochwertig erwiesen haben, werden sie in dieser Arbeit wiederverwendet. 
Dieser Ansatz reduziert den Entwicklungsaufwand und baut auf einer validierten Datenressource auf.
% Ja, ist relevant. Ein Leser würde sonst davon ausgehen, dass extra Embeddings für diese Arbeit rezeugt wurden.
% Wenn nur die Referenz zur "semantischen Anzeigenausspielung" gemeint ist, ja könnte man weglassen.

Die \texttt{user\_pseudo\_id} ist ein pseudonymer Geräte-/Browser-Identifier. 
Sie bleibt auf demselben Gerät/Browser meist über mehrere Sitzungen stabil, kann sich jedoch durch Cookie-/App-Resets 
oder Geräte-/Browserwechsel ändern. Eine typische \texttt{user\_pseudo\_id} hat beispielsweise das Format 
\texttt{18475638.1694782345}.

Für eingeloggte Nutzer wird zusätzlich eine eindeutige, geräteübergreifende 
\texttt{user\_id} erfasst. Eine Analyse der Nutzerbasis im Untersuchungszeitraum (Januar bis März 2025) zeigt jedoch, 
dass mit 99,01\,\% der weitaus größte Teil der Nutzer anonym auf das Angebot zugreift und somit nur über eine 
\texttt{user\_pseudo\_id} verfügt.

Um ein Empfehlungssystem zu entwickeln, das der gesamten Leserschaft und nicht nur der kleinen Kohorte 
eingeloggter Nutzer dient, wurde die \texttt{user\_pseudo\_id} konsequent als primärer Schlüssel für die Personalisierung 
verwendet. Dieser Ansatz ist praxistauglich, da (i) die \texttt{user\_pseudo\_id} auf demselben Gerät über mehrere 
Sitzungen hinreichend stabil ist, um kurz- bis mittelfristige Präferenzen zu lernen, und (ii) im Nachrichtenkontext 
vor allem jüngste Interaktionen und der unmittelbare Artikelkontext prädiktiv sind. Letzteres wird durch die Hybridisierung 
genutzt: Der \ac{CBF}-Anteil arbeitet kontextuell, während der \ac{NCF}-Anteil gerätebezogene Wiederholungsmuster erfasst.

\subsection{Systemarchitektur}
Die technologische Architektur in Abbildung~\ref{fig:architektur} folgt einem cloud-nativen Microservice-Ansatz auf der 
\ac{GCP}. Diese Architektur wurde gewählt, da sie durch lose gekoppelte, unabhängige Dienste eine hohe Skalierbarkeit, 
Wartbarkeit und technologische Flexibilität ermöglicht (vgl. \cite{Newman_Microservices_2015}). Als zentraler 
Orchestrator dient ein in Python implementierter Service auf Basis von FastAPI. Der Service nimmt Anfragen entgegen, 
steuert die Modell-Endpunkte, aggregiert die Teilergebnisse und führt die Hybridisierung aus. Das Design ist modular, 
um künftig alternative Hybridisierungsstrategien mit geringem Integrationsaufwand aufnehmen zu können. 
Für die latenzkritische Online-Auslieferung werden der Artikelkorpus und Embeddings in einer operativen 
Datenbank vorgehalten; die ML-Modelle sind auf Vertex~AI\footnote{Siehe \url{https://cloud.google.com/vertex-ai}} deployt.
\input{content/figures/architektur.tex}

\label{sec:api_design}
Das Herzstück des Systems bildet der API-Service, der die externe Schnittstelle und die interne Orchestrierung 
bereitstellt. Die API exponiert einen REST-Endpunkt unter \texttt{/v1/recommendations} mit einem JSON-basierten 
Datenvertrag. Eine Anfrage umfasst die \texttt{user\_pseudo\_id}, die \texttt{article\_id} als Kontext sowie die 
gewünschte Hybridisierungsstrategie. Die Implementierung nutzt die asynchrone Leistungsfähigkeit von FastAPI 
(\ac{ASGI}) und orchestriert pro Anfrage parallele Aufrufe der untergeordneten ML-Dienste und der Datenbank. 
Nach dem Zusammenführen der Teilergebnisse wird die Hybridisierungslogik angewandt und die finale Empfehlungsliste 
zurückgegeben. Eingebaute Schema-Validierung und die automatische Generierung einer interaktiven API-Dokumentation 
unterstützen eine robuste Integration.

\label{sec:cbf_service}
Das \ac{CBF}-Retrieval erfolgt über einen Vektorindex (Vertex~AI Vector Search) auf den 
3072-dimensionale Artikel-Embeddings. Abfragen nutzen L2-normalisierte Vektoren und \ac{MIPS}; 
pro Kontextartikel werden die Top-$K$ semantisch ähnlichsten Artikel mit niedriger Latenz 
geliefert. Die zugrunde liegenden \ac{ANN}-Prinzipien und der Latenz–Recall-Trade-off 
sind in Abschnitt~\ref{sec:cbf} erläutert.

\label{sec:ncf_service}
Als kollaborative Komponente kommt ein \ac{NCF}-Modell zum Einsatz, 
das implizites Feedback verarbeitet und nichtlineare 
Nutzer–Item-Interaktionen modelliert (methodische Details siehe Abschnitt~\ref{sec:cf}). 
Das trainierte Modell wird als Echtzeit-Endpoint bereitgestellt und vom 
Orchestrator parallel zum \ac{CBF}-Dienst abgefragt; die Ergebnisse werden mittels 
gewichteter Hybridisierung kombiniert. Effekte wie Popularity Bias werden in der 
Hybridisierung gezielt adressiert (vgl. \ref{sec:hybrid}).

\subsection{Datenbasis und Einschränkungen}
\label{sec:data}
Der Datensatz \textit{SM-News-Jan25} umfasst ausschließlich \ac{GA4}-Interaktionsdaten des Nachrichtenportals 
schwaebische.de aus dem Januar 2025.


Um sicherzustellen, dass das Modell ausschließlich auf relevanten Nutzerinteraktionen trainiert wird, 
wurde der Rohdatensatz der \texttt{page\_view}-Events aus \ac{GA4} einem entscheidenden Filterschritt unterzogen. 
Ein \texttt{page\_view}-Event wird nicht nur für Artikel, sondern auch für Übersichts- oder Kategorieseiten ausgelöst. 
Daher wurden nur solche Events für die weitere Analyse berücksichtigt, deren zugehöriger Seitenpfad einem vordefinierten 
Muster für Artikelseiten entspricht. Der resultierende Datensatz repräsentiert somit ausschließlich explizite 
Artikelaufrufe.


Aus Kostengründen wird das NCF-Modell auf den ersten drei Wochen trainiert und in der vierten Woche getestet. 
Eine zentrale Eigenschaft des Trainingsdatensatzes ist die in Abbildung~\ref{fig:artikelverteilung_train} gezeigte stark 
rechtsschiefe Verteilung der Artikelpopularität als auch der in Abbildung~\ref{fig:nutzerverteilung_train}
gezeigten Nutzeraktivität (Long-Tail-Verteilung), ein für Mediendaten typisches Muster und eine Kernherausforderung für 
Empfehlungssysteme (vgl. \cite{wu_personalized_2022, raza_news_2020}).
\input{content/figures/artikelverteilung_train.tex}

Die Long-Tail-Struktur manifestiert sich in zwei Dimensionen:
\begin{itemize}
    \item \textbf{Artikelpopularität:} Wie in Abbildung~\ref{fig:artikelverteilung_train} ersichtlich, 
    konzentriert sich ein \newline überproportional großer Anteil der Seitenaufrufe auf wenige virale „Hit“-Artikel 
    (Kopf der Verteilung). Die kurze Lebensdauer von Nachrichtenartikeln verstärkt diesen Effekt zusätzlich.
    \item \textbf{Nutzeraktivität:} Analog zeigt sich beim Nutzerverhalten eine kleine Kohorte hochaktiver 
    „Power-Nutzer“, die einen Großteil der Artikelaufrufe generiert, während die Mehrheit nur sporadisch interagiert.
\end{itemize}
Diese ungleiche Verteilung induziert einen inhärenten Popularity Bias: Naive Modelle empfehlen tendenziell 
wiederholt dieselben Bestseller-Artikel, was Personalisierung untergräbt und das Risiko einer Filterblase erhöht. 
Gleichzeitig entsteht ein Kaltstart-Problem für Nischeninhalte im Long Tail. Eine zentrale Zielsetzung 
dieser Arbeit ist folglich die Konzeption eines Systems, das den Popularity Bias aktiv ausbalanciert und 
relevante Nischeninhalte an passende Nutzer ausspielt (vgl. \cite{Abdollahpouri_Popularity_Bias_2019}).
\input{content/figures/userverteilung_train.tex}

Die statistischen Kennzahlen des Trainingsdatensatzes sind in Tabelle~\ref{tab:train_stats} zusammengefasst.
\input{content/tables/train_stats.tex}

Zur Nutzung der PageView-Events im \ac{NCF}-Modell werden diese in eine \newline User–Item-Interaktionsmatrix überführt. 
Zeilen repräsentieren eindeutige Nutzer, Spalten eindeutige Artikel des Trainingszeitraums. 
Eine Zelle $(i,j)$ erhält den Wert 1, wenn Nutzer $i$ mit Artikel $j$ interagiert hat, andernfalls 0. 
Die resultierende binäre Matrix mit circa 2{,}3~Mio.\ Nutzern und 104{,}000 Artikeln weist eine Dichte 
von unter 0{,}005\,\% auf und ist damit extrem dünn besetzt. Diese Sparsity ist für \ac{CF}-Modelle herausfordernd, 
da je Nutzer nur wenige Interaktionen im Verhältnis zur Gesamtheit der Artikel vorliegen und Generalisierung auf 
neue User–Item-Paare erschwert wird.

Bei der Interpretation der Ergebnisse sind folgende Limitationen zu berücksichtigen:
\begin{itemize}
    \item \textbf{Zeitlicher Rahmen:} Der Datensatz deckt ausschließlich den Januar 2025 ab und bildet damit 
    eine Momentaufnahme. Saisonale Effekte (z.\,B. Feiertage) oder längerfristige Trends können nicht erfasst werden.
    \item \textbf{Implizites Feedback:} Als Signal dienen ausschließlich Artikelaufrufe. Dieses implizite Feedback ist 
    zwar reichhaltig, jedoch mehrdeutig: Ein Artikelaufruf ist kein direkter Indikator für Zufriedenheit 
    (z.\,B. bei sofortigem Absprung). Weitere Signale wie Verweildauer werden im Prototyp nicht berücksichtigt.
    \item \textbf{Offline-Evaluation:} Die Modellgüte wird offline auf historischen Daten anhand etablierter 
    Metriken (z.\,B. \ac{nDCG}) evaluiert. Die tatsächliche Wirkung auf Nutzerverhalten im 
    Live-Betrieb lässt sich damit nur approximieren. Ein Online-A/B-Test wäre der nächste Schritt, 
    um den Business Impact auf KPIs wie Sitzungsdauer oder Nutzerbindung zu messen.
\end{itemize}